{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Density clustering algorithm from Montreal Gazette data\n",
    "Import the data, cluster this with different algorithms based on frequency and severity of accidents, export as json or geojson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dependencies\n",
    "import csv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import folium\n",
    "\n",
    "import matplotlib.colors as clrs\n",
    "import matplotlib.cm as cm\n",
    "\n",
    "from sklearn.cluster import DBSCAN, KMeans\n",
    "from geojson import Feature, FeatureCollection, Point\n",
    "from geopy.geocoders import Nominatim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_color(radius):\n",
    "    # min and max cluster size\n",
    "    norm = clrs.Normalize(vmin=2, vmax=7) # Min/max cluster size\n",
    "    m = cm.ScalarMappable(norm=norm, cmap='YlOrRd') # Choose colormap (from YeLlow to ReD)\n",
    "    rgbs = m.to_rgba(radius)[:-1] # Remove opacity\n",
    "    return clrs.rgb2hex(rgbs) # Turn into hex, because folium.Polyline doesn't take rgb\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17965\n",
      "4133\n"
     ]
    }
   ],
   "source": [
    "# Read collision file\n",
    "df = pd.read_csv('../data/collisions.csv',encoding='latin1')\n",
    "print(len(df))\n",
    "# Keep only those that have \"status = OK\" and \"type = bike\"\n",
    "df.drop(df[~((df['status'] == 'OK') & (df['type'] == 'bike'))].index,inplace = True)\n",
    "df = df[['lat1','lng1','nb_grave','nb_leger','nb_mort']]\n",
    "print(len(df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lat1         956.063292\n",
      "lng1       -1546.204715\n",
      "nb_grave       0.000000\n",
      "nb_leger       5.000000\n",
      "nb_mort       21.000000\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(np.sum(df[df['nb_mort'] != 0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Difference between (lat1,lng1) and (lat,lng) is that (lat1,lng1) is the center of the intersection, while (lat,lng) refers to a specific part of the intersection. We will proceed with the center of the intersection. We then expand the dataset via the frequency of accidents, where nb_grave counts for 3 and nb_mort counts for 6."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "geo_list = []\n",
    "for index, row in df.iterrows():\n",
    "    [geo_list.append([row[0],row[1]]) for _ in range(int(3*row[2]+row[3]+6*row[4]))]\n",
    "df_geo = pd.DataFrame(geo_list,columns=['lat','lng'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have our list of latitude and longitude points, and we can start to compute clusters. We used a hyperparameter search to compare different-sized clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "for paramloop in hyperparameter:\n",
    "    for param in paramloop:\n",
    "        db = DBSCAN(eps=2,min_samples=20)\n",
    "        y_db = db.fit_predict(df_geo)\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "db = DBSCAN(eps=0.00025, min_samples=5)\n",
    "db.fit(df_geo)\n",
    "core_samples_mask = np.zeros_like(db.labels_, dtype=bool)\n",
    "core_samples_mask[db.core_sample_indices_] = True\n",
    "labels = db.labels_\n",
    "\n",
    "# Number of clusters in labels, ignoring noise if present.\n",
    "n_clusters_ = len(set(labels)) - (1 if -1 in labels else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "172\n"
     ]
    }
   ],
   "source": [
    "print(n_clusters_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_means = []\n",
    "for label in range(n_clusters_):\n",
    "    lat = df_geo[labels == label].mean(axis=0)['lat']\n",
    "    lng = df_geo[labels == label].mean(axis=0)['lng']\n",
    "    count = np.sum(labels == label)\n",
    "    cluster_means.append([lat,lng,count])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/thomasr/tensorflow/lib/python3.6/site-packages/geopy/geocoders/osm.py:143: UserWarning: Using Nominatim with the default \"geopy/1.17.0\" `user_agent` is strongly discouraged, as it violates Nominatim's ToS https://operations.osmfoundation.org/policies/nominatim/ and may possibly cause 403 and 429 HTTP errors. Please specify a custom `user_agent` with `Nominatim(user_agent=\"my-application\")` or by overriding the default `user_agent`: `geopy.geocoders.options.default_user_agent = \"my-application\"`. In geopy 2.0 this will become an exception.\n",
      "  UserWarning\n"
     ]
    }
   ],
   "source": [
    "geolocator = Nominatim()\n",
    "location = geolocator.geocode(\"McGill University Montreal Quebec\")\n",
    "lat_mon = float(location.raw['lat'])\n",
    "lng_mon = float(location.raw['lon'])\n",
    "m = folium.Map(location=[lat_mon,lng_mon],tiles=\"Stamen Toner\",zoom_start=14)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for lat,lng,radius in cluster_means:\n",
    "    folium.CircleMarker(location = (lat,lng),radius = np.sqrt(10*radius),color = get_color(np.sqrt(radius)),fill=True,fill_opacity = 0.8).add_to(m)\n",
    "m.save('../hotspots.html')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_means = pd.DataFrame(cluster_means,columns = ['lat','lng','weight'])\n",
    "df_means.to_csv('../data/cluster_means.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2rc2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
